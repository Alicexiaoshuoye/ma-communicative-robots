{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from csv import reader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer and model \n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model =T5ForConditionalGeneration.from_pretrained('/Users/cayadehaas/PycharmProjects/Communicative_Robots/triple2text.pt', \n",
    "                                                return_dict=True, config='/Users/cayadehaas/PycharmProjects/Communicative_Robots/t5-base-config.json')\n",
    "def generate(text,model,tokenizer):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(\"WebNLG:{} </s>\".format(text), \n",
    "                               return_tensors=\"pt\")  \n",
    "    outputs = model.generate(input_ids)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> The Motor Sport Sport Vision is located in Fawkham and its HQ is Faw\n"
     ]
    }
   ],
   "source": [
    "#create an empty dataframe with generated sentences as column\n",
    "df = pd.DataFrame(columns=['generated_sentences'])\n",
    "#open triple file in read mode\n",
    "with open('/Users/cayadehaas/PycharmProjects/Communicative_Robots/output_with_sentences.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Iterate over each row in the csv using reader object\n",
    "    for row in csv_reader:\n",
    "        #remove the brackets from each row to make it the right format into the tokenizer\n",
    "        row = ''.join(row[-2])\n",
    "        model.eval()\n",
    "        input_ids = tokenizer.encode(row, return_tensors=\"pt\")  # Batch size 1\n",
    "        outputs = model.generate(input_ids)\n",
    "        sentence = tokenizer.decode(outputs[0])\n",
    "        #add generated sentences to dataframe\n",
    "        df = df.append({'generated_sentences': sentence}, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the target_text from the test data\n",
    "test_df=pd.read_csv('/Users/cayadehaas/PycharmProjects/Communicative_Robots/output_with_sentences.csv', header=None)\n",
    "target_text = test_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MotorSport Vision is located in the city of Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MotorSport Vision is located in the city of Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MotorSport Vision is located in Fawkham.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ciudad Ayala is a city with population density...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The city of Ciudad Ayala, with a population of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>Member of the entertainment industry, The GMA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>GMA New Media is located in the GMA Network Ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>Ciudad Ayala is in the country of Mexico and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>Ciudad Ayala is a Mexican city located in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>Ciudad Ayala located in the country of Mexico ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2622 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       target_sentences\n",
       "0     MotorSport Vision is located in the city of Fa...\n",
       "1     MotorSport Vision is located in the city of Fa...\n",
       "2              MotorSport Vision is located in Fawkham.\n",
       "3     Ciudad Ayala is a city with population density...\n",
       "4     The city of Ciudad Ayala, with a population of...\n",
       "...                                                 ...\n",
       "2617  Member of the entertainment industry, The GMA ...\n",
       "2618  GMA New Media is located in the GMA Network Ce...\n",
       "2619  Ciudad Ayala is in the country of Mexico and i...\n",
       "2620  Ciudad Ayala is a Mexican city located in the ...\n",
       "2621  Ciudad Ayala located in the country of Mexico ...\n",
       "\n",
       "[2622 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #create df from target_text\n",
    "target_df = pd.DataFrame(columns=['target_sentences'])\n",
    "target_df['target_sentences'] = target_text\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate results and save as csv\n",
    "result = pd.concat([df, target_df], axis=1, join='inner')\n",
    "result.to_csv('generated_sentences_vs_target_sentences.csv', mode='w', header=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
